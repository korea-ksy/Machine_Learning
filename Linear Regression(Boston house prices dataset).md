# ğŸŒ Linear Regression 
-Scikit-learn & One-hot encoding

## scikit-learn

:pythonìœ¼ë¡œ Traditional Machine Learning ì•Œê³ ë¦¬ì¦˜ë“¤ì„ êµ¬í˜„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬

## scikit-learnì˜ ì¥ì 

- íŒŒì´ì¬ì˜ ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ê³¼ì˜ í˜¸í™˜ì„±ì´ ì¢‹ìŒ(Numpy, pandas, Matplotlib ë“±)
- ì „ì²´ì— ê±¸ì³ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ë§¤ìš° ê°„ë‹¨í•˜ê²Œ ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ë“¤ì„ ì ìš©í•  ìˆ˜ ìˆìŒ

### 1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°

2. Train/ Test setìœ¼ë¡œ ë°ì´í„° ë‚˜ëˆ„ê¸°

3. ëª¨ë¸ ê°ì²´(Model Instance)ìƒì„±í•˜ê¸°

4. ëª¨ë¸ í•™ìŠµ ì‹œí‚¤ê¸°(Model fitting)

5. ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡í•˜ê¸° (predict on test data)

### 1-1. (ë¯¸êµ­ ë³´ìŠ¤í„´ì˜ ì£¼íƒ ê°€ê²©) ë°ì´í„° ì½ì–´ë“¤ì´ê¸°

### 1) Features

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
```

### df_data (Data, x)

- 0 :Â **ë²”ì£„ìœ¨**
- 1 :Â **25,000 í‰ë°©í”¼íŠ¸ë¥¼ ì´ˆê³¼í•˜ëŠ” ê±°ì£¼ì§€ì—­ ë¹„ìœ¨**
- 2 :Â **ë¹„ì†Œë§¤ìƒì—…ì§€ì—­ ë©´ì  ë¹„ìœ¨**
- 3 :Â **ì°°ìŠ¤ê°•ì˜ ê²½ê³„ì— ìœ„ì¹˜í•œ ê²½ìš°ëŠ” 1, ì•„ë‹ˆë©´ 0**
- 4 :Â **ì¼ì‚°í™”ì§ˆì†Œ ë†ë„**
- 5 :Â **ì£¼íƒë‹¹ ë°© ìˆ˜ (ê±°ì‹¤ ì™¸ subroom)**
- 6 :Â **1940ë…„ ì´ì „ì— ê±´ì¶•ëœ ì£¼íƒì˜ ë¹„ìœ¨**
- 7 :Â **ì§ì—…ì„¼í„°ì˜ ê±°ë¦¬**
- 8 :Â **ë°©ì‚¬í˜• ê³ ì†ë„ë¡œê¹Œì§€ì˜ ê±°ë¦¬**
- 9 :Â **ì¬ì‚°ì„¸ìœ¨**
- 10 :Â **í•™ìƒ/êµì‚¬ ë¹„ìœ¨**
- 11 :Â **ì¸êµ¬ ì¤‘ í‘ì¸ ë¹„ìœ¨**
- 12 :Â **ì¸êµ¬ ì¤‘ í•˜ìœ„ ê³„ì¸µ ë¹„ìœ¨**

```python
f_data = pd.read_excel('/content/drive/MyDrive/á„á…¡á„á…¡á„‹á…© sw ai á„Œá…®á†¼á„€á…³á†¸ 2(part5)/á„‰á…µá†¯á„‰á…³á†¸ á„‘á…¡á„‹á…µá†¯/2. Scikit-learn (Answer)/boston_house_data.xlsx',index_col=0) # ì—‘ì…€ íŒŒì¼ ì½ê¸°
df_data.head() # ìœ—ë¶€ë¶„ë§Œ ë³´ë ¤ë©´?

#Column == Attribute == Dimension == Feature(only X_data)
```

|  | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8** | **9** | **10** | **11** | **12** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | 0.00632 | 18.0 | 2.31 | 0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1 | 296 | 15.3 | 396.90 | 4.98 |
| **1** | 0.02731 | 0.0 | 7.07 | 0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2 | 242 | 17.8 | 396.90 | 9.14 |
| **2** | 0.02729 | 0.0 | 7.07 | 0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2 | 242 | 17.8 | 392.83 | 4.03 |
| **3** | 0.03237 | 0.0 | 2.18 | 0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3 | 222 | 18.7 | 394.63 | 2.94 |
| **4** | 0.06905 | 0.0 | 2.18 | 0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3 | 222 | 18.7 | 396.90 | 5.33 |

# ğŸŒFeature Normalization (Scailing)

### Numercial Column(Variable)

- > Min-max algorithm or Standardization

### Categorical Column(Variable)

- > One-hot encoding

```python
df_data[8].value_counts(sort=0).index # .Keys()
# from collections import Counter
# Counter(df_data[3])
```

### **2) Target**

```python
df_target = pd.read_excel('/content/drive/MyDrive/á„á…¡á„á…¡á„‹á…© sw ai á„Œá…®á†¼á„€á…³á†¸ 2(part5)/á„‰á…µá†¯á„‰á…³á†¸ á„‘á…¡á„‹á…µá†¯/2. Scikit-learn (Answer)/boston_house_target.xlsx', index_col=0)
df_target.head()
```

|  | **0** |
| --- | --- |
| **0** | 24.0 |
| **1** | 21.6 |
| **2** | 34.7 |
| **3** | 33.4 |
| **4** | 36.2 |

### df_target (Target, y)

- Town ë‚´ ì£¼íƒ ê°€ê²©ì˜ ì¤‘ì•™ê°’ (ë‹¨ìœ„ : $1,000)

### **3) Features & Target í•©ì³ì„œ ì‚´í´ë³´ê¸°**

```python
#A.join(B)
#pd.merge(A,B,left_on="Aê¸°ì¤€ì—¬ë¥´ right_on='Bê¸°ì¤€ì—´", how='inner')
#pd.concat([A,B],axis=1)

df_main = pd.concat([df_data, df_target], axis=1) # concatenate
df_main.head()
```

|  | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8** | **9** | **10** | **11** | **12** | **0** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | 0.00632 | 18.0 | 2.31 | 0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1 | 296 | 15.3 | 396.90 | 4.98 | 24.0 |
| **1** | 0.02731 | 0.0 | 7.07 | 0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2 | 242 | 17.8 | 396.90 | 9.14 | 21.6 |
| **2** | 0.02729 | 0.0 | 7.07 | 0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2 | 242 | 17.8 | 392.83 | 4.03 | 34.7 |
| **3** | 0.03237 | 0.0 | 2.18 | 0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3 | 222 | 18.7 | 394.63 | 2.94 | 33.4 |
| **4** | 0.06905 | 0.0 | 2.18 | 0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3 | 222 | 18.7 | 396.90 | 5.33 | 36.2 |

```python
#ì—´ ì´ë¦„ í†µì§¸ë¡œ ë°”ê¾¸ê¸°
df_main.columns = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV'] 
df_main.head()
```

|  | **CRIM** | **ZN** | **INDUS** | **CHAS** | **NOX** | **RM** | **AGE** | **DIS** | **RAD** | **TAX** | **PTRATIO** | **B** | **LSTAT** | **MEDV** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | 0.00632 | 18.0 | 2.31 | 0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1 | 296 | 15.3 | 396.90 | 4.98 | 24.0 |
| **1** | 0.02731 | 0.0 | 7.07 | 0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2 | 242 | 17.8 | 396.90 | 9.14 | 21.6 |
| **2** | 0.02729 | 0.0 | 7.07 | 0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2 | 242 | 17.8 | 392.83 | 4.03 | 34.7 |
| **3** | 0.03237 | 0.0 | 2.18 | 0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3 | 222 | 18.7 | 394.63 | 2.94 | 33.4 |
| **4** | 0.06905 | 0.0 | 2.18 | 0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3 | 222 | 18.7 | 396.90 | 5.33 | 36.2 |

```python
df_main.describe() # description
```

|  | **CRIM** | **ZN** | **INDUS** | **CHAS** | **NOX** | **RM** | **AGE** | **DIS** | **RAD** | **TAX** | **PTRATIO** | **B** | **LSTAT** | **MEDV** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **count** | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 | 506.000000 |
| **mean** | 3.593761 | 11.363636 | 11.136779 | 0.069170 | 0.554695 | 6.284634 | 68.574901 | 3.795043 | 9.549407 | 408.237154 | 18.455534 | 356.674032 | 12.653063 | 22.532806 |
| **std** | 8.596783 | 23.322453 | 6.860353 | 0.253994 | 0.115878 | 0.702617 | 28.148861 | 2.105710 | 8.707259 | 168.537116 | 2.164946 | 91.294864 | 7.141062 | 9.197104 |
| **min** | 0.006320 | 0.000000 | 0.460000 | 0.000000 | 0.385000 | 3.561000 | 2.900000 | 1.129600 | 1.000000 | 187.000000 | 12.600000 | 0.320000 | 1.730000 | 5.000000 |
| **25%** | 0.082045 | 0.000000 | 5.190000 | 0.000000 | 0.449000 | 5.885500 | 45.025000 | 2.100175 | 4.000000 | 279.000000 | 17.400000 | 375.377500 | 6.950000 | 17.025000 |
| **50%** | 0.256510 | 0.000000 | 9.690000 | 0.000000 | 0.538000 | 6.208500 | 77.500000 | 3.207450 | 5.000000 | 330.000000 | 19.050000 | 391.440000 | 11.360000 | 21.200000 |
| **75%** | 3.647423 | 12.500000 | 18.100000 | 0.000000 | 0.624000 | 6.623500 | 94.075000 | 5.188425 | 24.000000 | 666.000000 | 20.200000 | 396.225000 | 16.955000 | 25.000000 |
| **max** | 88.976200 | 100.000000 | 27.740000 | 1.000000 | 0.871000 | 8.780000 | 100.000000 | 12.126500 | 24.000000 | 711.000000 | 22.000000 | 396.900000 | 37.970000 | 50.000000 |

### **1-2. Dataframe ì„ Numpy array (ë°°ì—´, í–‰ë ¬)ë¡œ ë°”ê¿”ì£¼ê¸°**

```python
boston_data = np.array(df_data)
boston_target = np.array(df_target)

pd.DataFrame(boston_data)
```

| **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8** | **9** | **10** | **11** | **12** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | 0.00632 | 18.0 | 2.31 | 0.0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1.0 | 296.0 | 15.3 | 396.90 |
| **1** | 0.02731 | 0.0 | 7.07 | 0.0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2.0 | 242.0 | 17.8 | 396.90 |
| **2** | 0.02729 | 0.0 | 7.07 | 0.0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2.0 | 242.0 | 17.8 | 392.83 |
| **3** | 0.03237 | 0.0 | 2.18 | 0.0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3.0 | 222.0 | 18.7 | 394.63 |
| **4** | 0.06905 | 0.0 | 2.18 | 0.0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3.0 | 222.0 | 18.7 | 396.90 |
| **...** | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |
| **501** | 0.06263 | 0.0 | 11.93 | 0.0 | 0.573 | 6.593 | 69.1 | 2.4786 | 1.0 | 273.0 | 21.0 | 391.99 |
| **502** | 0.04527 | 0.0 | 11.93 | 0.0 | 0.573 | 6.120 | 76.7 | 2.2875 | 1.0 | 273.0 | 21.0 | 396.90 |
| **503** | 0.06076 | 0.0 | 11.93 | 0.0 | 0.573 | 6.976 | 91.0 | 2.1675 | 1.0 | 273.0 | 21.0 | 396.90 |
| **504** | 0.10959 | 0.0 | 11.93 | 0.0 | 0.573 | 6.794 | 89.3 | 2.3889 | 1.0 | 273.0 | 21.0 | 393.45 |
| **505** | 0.04741 | 0.0 | 11.93 | 0.0 | 0.573 | 6.030 | 80.8 | 2.5050 | 1.0 | 273.0 | 21.0 | 396.90 |

506 rows Ã— 13 columns

```python
type(boston_data) #íƒ€ì…
boston_data.shape #ì°¨ì› ìˆ˜ í™•ì¸

>>> (506, 13)
```

### **2. Feature ì„ íƒí•˜ê¸°**

```python
# Use only one feature 

# í•­ìƒ í–‰ë ¬ í˜•íƒœë¡œ ë½‘ì•„ì„œ ëª¨ë¸ì—ê²Œ ë˜ì ¸ì¤˜ì•¼ í•©ë‹ˆë‹¤
boston_X = boston_data[:, 12:13] # ì¸êµ¬ ì¤‘ í•˜ìœ„ ê³„ì¸µ ë¹„ìœ¨ 
boston_X
# boston_X = boston_data[:, 12]
# boston_X.reshape(-1,1) <- 1ì—´ë¡œ ë§ì¶°ì£¼ê³  í–‰ì˜ ìˆ˜ëŠ” ì•Œì•„ì„œ

boston_Y = boston_target
boston_Y
```

### **3. Training & Test set ìœ¼ë¡œ ë‚˜ëˆ ì£¼ê¸°**

```python
from sklearn import model_selection

x_train, x_test, y_train, y_test = model_selection.train_test_split(boston_X, boston_Y, test_size=0.3, random_state=0)
# random_state (random_seed or seed) : make the result reproducible
# random_state ê°’ì— ë”°ë¼ ëœë¤í•œ ê°’ì´ ë‹¬ë¼ì§(ê°™ì€ random_stateê°’ë¼ë¦¬ëŠ” ê°’ì´ ê°™ìŒ)
```

```python
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

>>>(354, 1)
	 (152, 1)
	 (354, 1)
	 (152, 1)
```

### **4. ë¹„ì–´ìˆëŠ” ëª¨ë¸ ê°ì²´ ë§Œë“¤ê¸°**

```python
from sklearn import linear_model

model = linear_model.LinearRegression() # ì„ í˜•íšŒê·€
```

### **5. ëª¨ë¸ ê°ì²´ í•™ìŠµì‹œí‚¤ê¸° (on training data)**

```python
# Train the model using the training sets

model.fit(x_train, y_train) # ëª¨ë¸ì— ë°ì´í„°ë¥¼ 'ë§ì¶°ì¤ë‹ˆë‹¤'
```

```python
print('Coefficients: ', model.coef_) # coefficient : ê³„ìˆ˜ -> a == -0.968

>>> Coefficients:  [[-0.96814078]]
```

```python
print('Intetcepts: ', model.intercept_) # intetcept: êµì°¨ì (yì ˆí¸) -> b == 34.789

>>> Intetcepts:  [34.78978059]

# y = -0.968 *x + 34.789
```

### **6. í•™ìŠµì´ ëë‚œ ëª¨ë¸ í…ŒìŠ¤íŠ¸í•˜ê¸° (on test data)**

```python
model.predict(x_train) # 'ì˜ˆì¸¡í•˜ë‹¤'
```

```python
# 354ê°œ Train ë°ì´í„°ì— ëŒ€í•œ Model ì˜ Mean squared error 
print('MSE(Training data) : ', np.mean((model.predict(x_train) - y_train) ** 2))
```

```
# Use this!
from sklearn.metrics import mean_squared_error

print('MSE(Training data) : ', mean_squared_error(model.predict(x_train), y_train))
```

```python
#152ê°œ Test ë°ì´í„°ì— ëŒ€í•œ Model ì˜ Mean squared error 
print('MSE(Test data) : ', mean_squared_error(model.predict(x_test), y_test))

>>> MSE(Test data) :  39.81715050474416
```

```python
#RMSE (Root mean squared error)

# Square root(ì œê³±ê·¼) of error
np.sqrt(mean_squared_error(model.predict(x_test), y_test))

>>> 6.310083240714354
```

### **7. ëª¨ë¸ ì‹œê°í™”**

```python
plt.figure(figsize=(10, 10))

plt.scatter(x_test, y_test, color="black") # Test data
plt.scatter(x_train, y_train, color="red", s=1) # Train data

plt.plot(x_test, model.predict(x_test), color="blue", linewidth=3) # Fitted line

plt.show()
```

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/68bb1ca2-fb4b-440f-8efe-40f62b774bc9/Untitled.png)
