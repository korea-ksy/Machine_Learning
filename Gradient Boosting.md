### ğŸ˜ Gradient Boosting(GBM)?

- ì£¼ìš” ì•™ìƒë¸” ì•Œê³ ë¦¬ì¦˜ì€ baggingê³¼ boostiongìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆê³ , Gradient boostingì€ boosting ê³„ì—´ì˜ ì•™ìƒë¸” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
- Boostingì´ë€ ì•½í•œ ë¶„ë¥˜ê¸°ë¥¼ ê²°í•©í•˜ì—¬ ê°•í•œ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“œëŠ” ê³¼ì •ì´ë‹¤.
- Gradient Boosting(GBM) ì€ ì”ì°¨ë¥¼ ì´ìš©í•˜ì—¬ ì´ì „ ëª¨í˜•ì˜ ì•½ì ì„ ë³´ì™„í•œë‹¤.
    
    â†’ í•˜ì§€ë§Œ ê³¼ëŒ€ì í•©ì´ ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” ë‹¨ì ì„ ì§€ë‹ˆê³  ìˆìŒ
    
- GBMì€ ìˆœì°¨ì ìœ¼ë¡œ ì í•©í•œ ë’¤ ì´ë“¤ì„ ì„ í˜• ê²°í•©í•œ ëª¨í˜•ì„ ìƒì„±í•œë‹¤

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a9943cca-db10-4d1f-a8ca-614738f31bb3/Untitled.png)

ROC Curve: ìˆ˜ì‹ ì ì¡°ì‘ íŠ¹ì„± ê³¡ì„ 

AUC = Area Under the ROC Curve (0.5~1) â†’ ROC Curve ë°‘ì˜ ë©´ì 

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets, model_selection, linear_model
from sklearn.metrics import mean_squared_error, accuracy_score, roc_curve, auc

# 1. Prepare the data (array!)
df_data = pd.read_excel('/content/drive/MyDrive/á„á…¡á„á…¡á„‹á…© sw ai á„Œá…®á†¼á„€á…³á†¸ 2(part5)/á„‰á…µá†¯á„‰á…³á†¸ á„‘á…¡á„‹á…µá†¯/2. Scikit-learn (Answer)/boston_house_data.xlsx', index_col=0)
df_target = pd.read_excel('/content/drive/MyDrive/á„á…¡á„á…¡á„‹á…© sw ai á„Œá…®á†¼á„€á…³á†¸ 2(part5)/á„‰á…µá†¯á„‰á…³á†¸ á„‘á…¡á„‹á…µá†¯/2. Scikit-learn (Answer)/boston_house_target.xlsx')
df_target['Label'] = df_target[0].apply(lambda x: 1 if x > df_target[0].mean() else 0 ) 
boston_data = np.array(df_data)
boston_target = np.array(df_target['Label'])

# 2. Feature selection
boston_X = boston_data[:,5:13] # ì£¼íƒë‹¹ ë°© ìˆ˜ & ì¸êµ¬ ì¤‘ í•˜ìœ„ ê³„ì¸µ ë¹„ìœ¨ 
boston_Y = boston_target

# 3. Train/Test split
x_train, x_test, y_train, y_test = model_selection.train_test_split(boston_X, boston_Y, test_size=0.3, random_state=0)

# 4. Create model object 
model = linear_model.LogisticRegression()

# 5. Train the model 
model.fit(x_train, y_train)

# 6. Test the model
print('Accuracy: ', accuracy_score(model.predict(x_test), y_test))

# 7. Visualize the model
pred_test = model.predict_proba(x_test) # Predict 'probability'
fpr, tpr, _ = roc_curve(y_true=y_test, y_score=pred_test[:,1]) # real y & predicted y (based on "Sepal width")
roc_auc = auc(fpr, tpr) # AUC ë©´ì ì˜ ê°’ (ìˆ˜ì¹˜)

plt.figure(figsize=(10, 10))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc="lower right")
plt.title("ROC curve")
plt.show()
```

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9bbbf53e-8a77-49c5-9793-2dbb3425dd92/Untitled.png)

```python
**plt.plot(fpr, tpr, color='darkorange', 
lw=2, label='ROC curve (area = %0.2f)' % roc_auc)**
```

- **fpr** : False Positive Rate, tpr: True Positive Rateë¥¼ xì¶•ê³¼ yì¶•ìœ¼ë¡œ í•˜ëŠ” ROC ê³¡ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.
- **color** : ê³¡ì„ ì˜ ìƒ‰ìƒì„ ì§€ì •í•©ë‹ˆë‹¤.
- **lw** : ê³¡ì„ ì˜ ë‘ê»˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
- **label** : ê³¡ì„ ì— ëŒ€í•œ ë¼ë²¨ì„ ì§€ì •í•©ë‹ˆë‹¤. roc_aucëŠ” ROC ê³¡ì„  ì•„ë˜ ë©´ì (AUC)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

```python
**plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')**
```

- [0, 1]ê³¼ [0, 1]ì„ ì—°ê²°í•˜ëŠ” ëŒ€ê°ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.
- color: ëŒ€ê°ì„ ì˜ ìƒ‰ìƒì„ ì§€ì •í•©ë‹ˆë‹¤.
- lw: ëŒ€ê°ì„ ì˜ ë‘ê»˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
- linestyle: ëŒ€ê°ì„ ì˜ ìŠ¤íƒ€ì¼ì„ ì§€ì •í•©ë‹ˆë‹¤.

### ***ps**

**TP= ì‹¤ì œ Positiveë¥¼ ëª¨ë¸ì´ Positiveë¡œ ì˜³ê²Œ ì˜ˆì¸¡í•œ ìˆ˜**

**TNÂ = ì‹¤ì œ Negativeë¥¼ ëª¨ë¸ì´ Negativeë¡œ ì˜³ê²Œ ì˜ˆì¸¡í•œ ìˆ˜**

**FP= ì‹¤ì œ Negativeë¥¼ ëª¨ë¸ì´ Positiveë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ìˆ˜**

**FNÂ = ì‹¤ì œ Positiveë¥¼ ëª¨ë¸ì´ Negativeë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ìˆ˜**

FPRì™€ TPRì€ Confusion Matrixì˜ ìš”ì†Œë“¤ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- FPRì€ ì‹¤ì œ Negativeì—ì„œ ëª¨ë¸ì´ Positiveë¼ê³  ì˜ˆì¸¡í•œ ë¹„ìœ¨ì„ ëœ»í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•©ë‹ˆë‹¤.
- FPRÂ =Â FPTN+FP

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5bc2475b-ba9a-48db-8ef4-e370f27b1e9c/Untitled.png)

- TPRì€ ì‹¤ì œ Positiveì—ì„œ ëª¨ë¸ì´ Positiveë¼ê³  ì˜ˆì¸¡í•œ ë¹„ìœ¨ì„ ëœ»í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•©ë‹ˆë‹¤.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a4ef7a68-ec54-4c92-a3ce-206cff30c04b/Untitled.png)

[Gradient Boosting regression â€” scikit-learn 0.20.4 documentation](https://scikit-learn.org/0.20/auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py)
