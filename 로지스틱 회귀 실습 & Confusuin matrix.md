# üêå **Logistic Regression Ïã§Ïäµ & Confusion matrix**

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn import datasets, model_selection, linear_model
from sklearn.metrics import mean_squared_error
```

## üêå **1-1. (ÎØ∏Íµ≠ Î≥¥Ïä§ÌÑ¥Ïùò Ï£ºÌÉù Í∞ÄÍ≤©) Îç∞Ïù¥ÌÑ∞ ÏùΩÏñ¥Îì§Ïù¥Í∏∞ & Binary label ÎßåÎì§Ïñ¥Ï£ºÍ∏∞**

```python
df_data = pd.read_excel('/content/drive/MyDrive/·Ñè·Ö°·Ñè·Ö°·Ñã·Ö© sw ai ·Ñå·ÖÆ·Üº·ÑÄ·Ö≥·Ü∏ 2(part5)/·Ñâ·Öµ·ÜØ·Ñâ·Ö≥·Ü∏ ·Ñë·Ö°·Ñã·Öµ·ÜØ/2. Scikit-learn (Answer)/boston_house_data.xlsx', index_col=0)
df_data.head()
```

|  | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8** | **9** | **10** | **11** | **12** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **0** | 0.00632 | 18.0 | 2.31 | 0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1 | 296 | 15.3 | 396.90 | 4.98 |
| **1** | 0.02731 | 0.0 | 7.07 | 0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2 | 242 | 17.8 | 396.90 | 9.14 |
| **2** | 0.02729 | 0.0 | 7.07 | 0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2 | 242 | 17.8 | 392.83 | 4.03 |
| **3** | 0.03237 | 0.0 | 2.18 | 0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3 | 222 | 18.7 | 394.63 | 2.94 |
| **4** | 0.06905 | 0.0 | 2.18 | 0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3 | 222 | 18.7 | 396.90 | 5.33 |

```python
df_target = pd.read_excel('/content/drive/MyDrive/·Ñè·Ö°·Ñè·Ö°·Ñã·Ö© sw ai ·Ñå·ÖÆ·Üº·ÑÄ·Ö≥·Ü∏ 2(part5)/·Ñâ·Öµ·ÜØ·Ñâ·Ö≥·Ü∏ ·Ñë·Ö°·Ñã·Öµ·ÜØ/2. Scikit-learn (Answer)/boston_house_target.xlsx', index_col=0)
df_target.head()
```

|  | **0** |
| --- | --- |
| **0** | 24.0 |
| **1** | 21.6 |
| **2** | 34.7 |
| **3** | 33.4 |
| **4** | 36.2 |

```python
# ÏßëÍ∞íÏùò ÌèâÍ∑†Í∞íÏù¥ ÏñºÎßàÏùºÍπåÏöî?
mean_price = df_target[0].mean()
mean_price

>>> 22.532806324110677
```

```python
df_target['Label'] = df_target[0].apply(lambda x: 1 if x > mean_price else 0 ) # ÏÉàÎ°úÏö¥ Ìï®ÏàòÎ•º 'Ï†ÅÏö©'Ìï¥Ï£ºÎ†§Î©¥?
df_target.head()

#ÏúÑÏóêÏÑú Íµ¨Ìïú ÌèâÍ∑†Í∞íÎ≥¥Îã§ ÌÅ¨Î©¥ 1 ÏûëÏúºÎ©¥ 0 
```

## üêå **1-2. Dataframe ÏùÑ Numpy array (Î∞∞Ïó¥, ÌñâÎ†¨)Î°ú Î∞îÍøîÏ£ºÍ∏∞**

```python
boston_data = np.array(df_data)
boston_target = np.array(df_target['Label'])
boston_target

array([1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,
       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,
       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,
       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,
       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,
       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) 
```

## üêå **2. Feature ÏÑ†ÌÉùÌïòÍ∏∞**

- 0 :¬†**Î≤îÏ£ÑÏú®**
- 1 :¬†**25,000 ÌèâÎ∞©ÌîºÌä∏Î•º Ï¥àÍ≥ºÌïòÎäî Í±∞Ï£ºÏßÄÏó≠ ÎπÑÏú®**
- 2 :¬†**ÎπÑÏÜåÎß§ÏÉÅÏóÖÏßÄÏó≠ Î©¥Ï†Å ÎπÑÏú®**
- 3 :¬†**Ï∞∞Ïä§Í∞ïÏùò Í≤ΩÍ≥ÑÏóê ÏúÑÏπòÌïú Í≤ΩÏö∞Îäî 1, ÏïÑÎãàÎ©¥ 0**
- 4 :¬†**ÏùºÏÇ∞ÌôîÏßàÏÜå ÎÜçÎèÑ**
- 5 :¬†**Ï£ºÌÉùÎãπ Î∞© Ïàò (Í±∞Ïã§ Ïô∏ subroom)**
- 6 :¬†**1940ÎÖÑ Ïù¥Ï†ÑÏóê Í±¥Ï∂ïÎêú Ï£ºÌÉùÏùò ÎπÑÏú®**
- 7 :¬†**ÏßÅÏóÖÏÑºÌÑ∞Ïùò Í±∞Î¶¨**
- 8 :¬†**Î∞©ÏÇ¨Ìòï Í≥†ÏÜçÎèÑÎ°úÍπåÏßÄÏùò Í±∞Î¶¨**
- 9 :¬†**Ïû¨ÏÇ∞ÏÑ∏Ïú®**
- 10 :¬†**ÌïôÏÉù/ÍµêÏÇ¨ ÎπÑÏú®**
- 11 :¬†**Ïù∏Íµ¨ Ï§ë ÌùëÏù∏ ÎπÑÏú®**
- 12 :¬†**Ïù∏Íµ¨ Ï§ë ÌïòÏúÑ Í≥ÑÏ∏µ ÎπÑÏú®**

```python
boston_X = boston_data[:,(5, 12)] # Ï£ºÌÉùÎãπ Î∞© Ïàò(5) & Ïù∏Íµ¨ Ï§ë ÌïòÏúÑ Í≥ÑÏ∏µ ÎπÑÏú®(12)
boston_X
boston_Y = boston_target
```

## üêå **3. Training & Test set ÏúºÎ°ú ÎÇòÎà†Ï£ºÍ∏∞**

```python
from sklearn import model_selection

x_train, x_test, y_train, y_test = model_selection.train_test_split(boston_X, boston_Y, test_size=0.3, random_state=0)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

>>> (354, 2)
		(152, 2)
		(354,)
		(152,)
```

## üêå **4. ÎπÑÏñ¥ÏûàÎäî Î™®Îç∏ Í∞ùÏ≤¥ ÎßåÎì§Í∏∞**

```python
model = linear_model.LogisticRegression() # Î°úÏßÄÏä§Ìã±ÌöåÍ∑Ä
```

## üêå **5. Î™®Îç∏ Í∞ùÏ≤¥ ÌïôÏäµÏãúÌÇ§Í∏∞ (on training data)**

```python
model.fit(x_train, y_train)
```

## üêå **6. ÌïôÏäµÏù¥ ÎÅùÎÇú Î™®Îç∏ ÌÖåÏä§Ìä∏ÌïòÍ∏∞ (on test data)**

```python
pred_test_ = model.predict(x_test)
pred_test_

array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,
       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,
       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,
       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1])
```

```python
# ÏñëÏÑ±/ÏùåÏÑ± ÌôïÎ•†ÏùÑ ÌôïÏù∏ÌïòÎ†§Î©¥?

# plot roc curve for test set
pred_test = model.predict_proba(x_test) # Predict 'probability'
pred_test

array([[2.71727138e-01, 7.28272862e-01],
       [5.14126251e-01, 4.85873749e-01],
       [5.72011266e-01, 4.27988734e-01],
       [9.94933971e-01, 5.06602928e-03],
       [7.70744299e-01, 2.29255701e-01],
       [5.07806637e-01, 4.92193363e-01],
       [7.68191608e-01, 2.31808392e-01],
       [5.56571586e-01, 4.43428414e-01],
       [9.37812032e-01, 6.21879678e-02],
       [5.76735788e-01, 4.23264212e-01],
       [9.93110093e-01, 6.88990666e-03],
       [9.88530491e-01, 1.14695093e-02],
       [9.66734148e-01, 3.32658524e-02],
       [9.99931971e-01, 6.80287144e-05],
       [7.73411904e-03, 9.92265881e-01],
       [5.49287966e-02, 9.45071203e-01],
       [6.30280147e-01, 3.69719853e-01],
       [3.26213034e-02, 9.67378697e-01],
       [1.13247007e-01, 8.86752993e-01],
       [5.34701631e-01, 4.65298369e-01],
       [2.41228758e-01, 7.58771242e-01],
       [8.12700869e-01, 1.87299131e-01],
       [8.86759215e-01, 1.13240785e-01],
       [2.29468197e-01, 7.70531803e-01],
       [7.15844986e-01, 2.84155014e-01],
       [9.85433064e-01, 1.45669362e-02],
       [8.93450425e-01, 1.06549575e-01],
       [9.61753263e-01, 3.82467368e-02],
       [1.49239635e-02, 9.85076036e-01],
       [9.66076142e-01, 3.39238577e-02],
       [9.74420812e-01, 2.55791880e-02],
       [9.13966573e-01, 8.60334271e-02],
       [5.75544988e-01, 4.24455012e-01],
       [8.00154741e-01, 1.99845259e-01],
       [4.09355893e-01, 5.90644107e-01],
       [9.33500378e-01, 6.64996221e-02],
       [9.99450691e-01, 5.49309494e-04],
       [5.39331552e-01, 4.60668448e-01],
       [9.64398012e-01, 3.56019882e-02],
       [9.97974838e-01, 2.02516166e-03],
       [4.39555425e-01, 5.60444575e-01],
       [9.20976636e-01, 7.90233640e-02],
       [4.87862293e-01, 5.12137707e-01],
       [9.89166226e-01, 1.08337737e-02],
       [3.39622078e-01, 6.60377922e-01],
       [4.18160120e-01, 5.81839880e-01],
       [9.59186762e-01, 4.08132381e-02],
       [9.23155145e-01, 7.68448546e-02],
       [9.99941302e-01, 5.86975360e-05],
       [3.66389636e-01, 6.33610364e-01],
       [9.18273583e-01, 8.17264175e-02],
       [9.82418719e-01, 1.75812813e-02],
       [7.68277772e-01, 2.31722228e-01],
       [9.21976763e-03, 9.90780232e-01],
       [9.78268469e-01, 2.17315308e-02],
       [9.52330598e-01, 4.76694016e-02],
       [8.61142582e-01, 1.38857418e-01],
       [8.47517134e-01, 1.52482866e-01],
       [6.90025318e-01, 3.09974682e-01],
       [9.72575668e-01, 2.74243322e-02],
       [4.23755620e-01, 5.76244380e-01],
       [8.18379345e-01, 1.81620655e-01],
       [6.11890463e-02, 9.38810954e-01],
       [6.17920841e-02, 9.38207916e-01],
       [9.42143532e-01, 5.78564681e-02],
       [8.39015452e-02, 9.16098455e-01],
       [9.52630943e-01, 4.73690565e-02],
       [9.88351919e-01, 1.16480806e-02],
       [9.74471838e-01, 2.55281623e-02],
       [7.25360906e-01, 2.74639094e-01],
       [7.32364267e-01, 2.67635733e-01],
       [4.33803079e-01, 5.66196921e-01],
       [1.13657837e-01, 8.86342163e-01],
       [6.19749132e-02, 9.38025087e-01],
       [2.18496568e-01, 7.81503432e-01],
       [9.99978866e-01, 2.11338164e-05],
       [1.10653228e-02, 9.88934677e-01],
       [6.31274937e-01, 3.68725063e-01],
       [3.86091547e-01, 6.13908453e-01],
       [9.18793780e-01, 8.12062197e-02],
       [2.18978410e-01, 7.81021590e-01],
       [8.70971996e-01, 1.29028004e-01],
       [8.58951047e-01, 1.41048953e-01],
       [1.17251361e-02, 9.88274864e-01],
       [8.73969119e-03, 9.91260309e-01],
       [1.88484605e-01, 8.11515395e-01],
       [7.04808041e-01, 2.95191959e-01],
       [9.54483076e-01, 4.55169244e-02],
       [2.38960385e-01, 7.61039615e-01],
       [9.83557833e-01, 1.64421667e-02],
       [9.31864641e-01, 6.81353594e-02],
       [9.95242281e-01, 4.75771865e-03],
       [2.57003724e-01, 7.42996276e-01],
       [1.08702780e-01, 8.91297220e-01],
       [3.94291078e-01, 6.05708922e-01],
       [5.05001316e-01, 4.94998684e-01],
       [9.99999322e-01, 6.78257496e-07],
       [1.54968361e-01, 8.45031639e-01],
       [9.64781841e-01, 3.52181591e-02],
       [8.89657715e-01, 1.10342285e-01],
       [4.55159528e-01, 5.44840472e-01],
       [7.14813079e-01, 2.85186921e-01],
       [3.38189397e-01, 6.61810603e-01],
       [6.18054035e-01, 3.81945965e-01],
       [5.21245611e-01, 4.78754389e-01],
       [8.16149714e-01, 1.83850286e-01],
       [9.99724943e-01, 2.75056881e-04],
       [9.64162388e-01, 3.58376118e-02],
       [4.93371890e-01, 5.06628110e-01],
       [3.52638932e-01, 6.47361068e-01],
       [5.72815671e-02, 9.42718433e-01],
       [9.99572037e-01, 4.27962534e-04],
       [9.84046418e-01, 1.59535815e-02],
       [9.46404747e-01, 5.35952528e-02],
       [9.99900466e-01, 9.95342786e-05],
       [9.14113492e-01, 8.58865076e-02],
       [9.99974854e-01, 2.51462387e-05],
       [6.34152244e-01, 3.65847756e-01],
       [9.99693557e-01, 3.06443474e-04],
       [1.13320929e-02, 9.88667907e-01],
       [7.33633543e-02, 9.26636646e-01],
       [9.99170311e-01, 8.29689161e-04],
       [9.71050561e-01, 2.89494389e-02],
       [8.43889315e-01, 1.56110685e-01],
       [6.24070775e-01, 3.75929225e-01],
       [9.77827418e-01, 2.21725818e-02],
       [7.33144904e-02, 9.26685510e-01],
       [9.88494358e-01, 1.15056416e-02],
       [5.60409345e-01, 4.39590655e-01],
       [7.27574818e-02, 9.27242518e-01],
       [9.50147850e-01, 4.98521498e-02],
       [9.98031324e-01, 1.96867584e-03],
       [9.79716873e-01, 2.02831268e-02],
       [9.22397735e-01, 7.76022650e-02],
       [9.92672947e-01, 7.32705321e-03],
       [4.55097311e-02, 9.54490269e-01],
       [6.81859400e-01, 3.18140600e-01],
       [9.99715718e-01, 2.84282026e-04],
       [1.50298199e-01, 8.49701801e-01],
       [9.99654459e-01, 3.45541085e-04],
       [9.96953381e-01, 3.04661883e-03],
       [8.87840078e-01, 1.12159922e-01],
       [6.57864490e-02, 9.34213551e-01],
       [1.15002142e-01, 8.84997858e-01],
       [2.39726039e-01, 7.60273961e-01],
       [9.37133513e-01, 6.28664865e-02],
       [4.44028114e-02, 9.55597189e-01],
       [6.21144479e-02, 9.37885552e-01],
       [9.93872229e-01, 6.12777127e-03],
       [9.99953182e-01, 4.68184743e-05],
       [7.69059703e-02, 9.23094030e-01],
       [1.21173269e-01, 8.78826731e-01]])
```

```python
from sklearn.metrics import accuracy_score # accuracy

# Î™®Îç∏ Î∂ÑÎ•òÏùò Ï†ïÌôïÎèÑ
print('Accuracy: ', accuracy_score(model.predict(x_test), y_test))

>>> Accuracy:  0.8223684210526315
```

---

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ad8b0c0d-1158-4983-b851-c518406e8b7a/Untitled.png)

1. Ïïî ÌôòÏûê ÌåêÎ≥Ñ Î¨∏Ï†ú

ÏïîÌôòÏûêÍ∞Ä ÎßûÎäîÎç∞ ÏïÑÎãàÎùºÍ≥† ÌåêÎ≥Ñ ÌïòÎäî False Negative(FN)Í∞Ä Í∞ÄÏû• Ï§ëÏöîÌïòÎØÄÎ°ú FNÍ∞íÏùÑ Ï§ÑÏù¥Í∏∞ ÏúÑÌï¥ ÎÖ∏Î†•

1. Ïä§Ìå∏ ÌåêÎ≥Ñ Î¨∏Ï†ú

Ïä§Ìå∏Ïù¥ ÏïÑÎãåÎç∞ Ïä§Ìå∏Ïù¥ÎùºÍ≥† ÌåêÎ≥Ñ ÌïòÎäî False positive (FP)Îäî Ï§ëÏöîÌïú Î¨∏ÏûêÍ∞Ä ÏôîÏùÑ Îïå Ïä§Ìå∏Ïù¥ÎùºÍ≥† Ï≤òÎ¶¨Ìï¥ÏÑú Î™ª ÏùΩÍ≤å Ìï† Ïàò ÏûàÍ∏∞ ÎïåÎ¨∏Ïóê FPÎ•º Ï§ÑÏù¥ÎèÑÎ°ù ÎÖ∏Î†•

## üêå Recall(Ïû¨ÌòÑÏú®)

Ïã§Ï†ú Ï†ïÎãµ positive Ï§ëÏóêÏÑú(Ïã§Ï†ú Ï∞∏Ïù∏ Í≤ÉÎì§ Ï§ë) TruePositiveÏùò ÌôïÎ•†(FN Ï§ëÏöî: ÌôïÎ•†ÏùÑ ÎÜíÏù¥Í∏∞ ÏúÑÌï¥)

‚Üí TP/TP+FN

## üêå Precision(Ï†ïÎ∞ÄÎèÑ)

ÏòàÏ∏° positiveÏ§ëÏóêÏÑú(Ï∞∏ Ïù¥ÎùºÍ≥† ÏòàÏ∏° Ìïú Í≤É Ï§ë) ÏßÑÏßú TPÏùò ÌôïÎ•†(FP Ï§ëÏöî)

‚Üí TP/Tp+FP

## üêå F1-Score

: Recall(R)Í≥º Precision(P)Ïùò Ï°∞Ìôî ÌèâÍ∑†

‚Üí **2*R*P/R+P**

### üêå **F-Beta Score**

: F1-ScoreÏùÄ RÍ≥º PÎ•º ÎèôÎì±ÌïòÍ≤å ÎëêÍ≥† Íµ¨ÌïòÏßÄÎßå, F-Beta scoreÏùÄ RÍ≥º PÏ§ë Ïñ¥Îäê Í≤ÉÏóê Îçî ÎπÑÏ§ëÏùÑ Îëò ÏßÄ 

  Í∞ÄÏ§ëÏπòÎ•º Ï†ÅÏö©Ìï† Ïàò ÏûàÎã§.
